"""
FanSense - Fixed Streamlit Visualization App
-------------------------------------
This module provides a Streamlit interface for visualizing fan engagement data.
Fixed for query parameter handling.
"""

import streamlit as st
import pandas as pd
import numpy as np
import psycopg2
import psycopg2.extras
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import json
from typing import Dict, List, Any, Tuple, Optional

# Database configuration
DB_CONFIG = {
    "dbname": "fansense",
    "user": "dee",
    "password": "",
    "host": "localhost",
    "port": 5432,
}

# Set page configuration
st.set_page_config(
    page_title="FanSense - Geo & Emotion-Based Fan Heatmaps",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Helper functions
def get_db_connection():
    """Create a database connection."""
    return psycopg2.connect(**DB_CONFIG)

def execute_query(query, params=None):
    """Execute a query and return results as a pandas DataFrame."""
    conn = get_db_connection()
    try:
        # Initialize param_values as an empty list
        param_values = []
        
        # Only assign values if params is provided
        if params is not None:
            # Convert to list if it's a dictionary
            if isinstance(params, dict):
                param_values = list(params.values())
            else:
                param_values = params
            
        # Execute the query using the appropriate parameter format
        df = pd.read_sql_query(query, conn, params=param_values if param_values else None)
        return df
    except Exception as e:
        st.error(f"Query execution error: {str(e)}")
        return pd.DataFrame()  # Return empty DataFrame on error
    finally:
        conn.close()

def get_available_hashtags():
    """Get list of hashtags in the database."""
    query = """
    SELECT DISTINCT unnest(hashtags) as hashtag 
    FROM tweets 
    WHERE hashtags IS NOT NULL
    ORDER BY hashtag;
    """
    df = execute_query(query)
    if df.empty:
        return []
    return df['hashtag'].tolist()

def get_date_range():
    """Get the min and max date in the database."""
    query = "SELECT MIN(created_at), MAX(created_at) FROM tweets;"
    df = execute_query(query)
    if df.empty or df.iloc[0, 0] is None:
        # Default to last 7 days if no data
        end_date = datetime.now()
        start_date = end_date - timedelta(days=7)
        return start_date, end_date
    return df.iloc[0, 0], df.iloc[0, 1]

def get_sentiment_data(hashtags=None, start_date=None, end_date=None):
    """Get sentiment data for visualization."""
    where_clauses = []
    params = []
    
    if start_date:
        where_clauses.append("created_at >= %s")
        params.append(start_date)
    
    if end_date:
        where_clauses.append("created_at <= %s")
        params.append(end_date)
    
    if hashtags:
        # Handle hashtags array parameter - this may require special handling
        # For now, we'll skip this as it's more complex
        pass
    
    where_clause = " AND ".join(where_clauses) if where_clauses else "1=1"
    
    query = f"""
    SELECT 
        date_trunc('hour', created_at) AS time_bucket,
        emotion,
        COUNT(*) AS tweet_count
    FROM tweets
    WHERE {where_clause}
    GROUP BY time_bucket, emotion
    ORDER BY time_bucket, emotion;
    """
    
    return execute_query(query, params if params else None)

def get_geo_sentiment_data(hashtags=None, start_date=None, end_date=None, emotion=None):
    """Get geo and sentiment data for heatmap visualization."""
    where_clauses = ["latitude IS NOT NULL AND longitude IS NOT NULL"]
    params = []
    
    if start_date:
        where_clauses.append("created_at >= %s")
        params.append(start_date)
    
    if end_date:
        where_clauses.append("created_at <= %s")
        params.append(end_date)
    
    if emotion and emotion != "All":
        where_clauses.append("emotion = %s")
        params.append(emotion)
    
    if hashtags:
        # Handle hashtags array parameter - this may require special handling
        # For now, we'll skip this as it's more complex
        pass
    
    where_clause = " AND ".join(where_clauses)
    
    query = f"""
    SELECT 
        latitude,
        longitude,
        location_address,
        city,
        country,
        emotion,
        COUNT(*) AS tweet_count
    FROM tweets
    WHERE {where_clause}
    GROUP BY latitude, longitude, location_address, city, country, emotion
    ORDER BY tweet_count DESC;
    """
    
    return execute_query(query, params if params else None)

def get_top_locations(hashtags=None, start_date=None, end_date=None):
    """Get top locations by tweet count."""
    where_clauses = ["city IS NOT NULL"]
    params = []
    
    if start_date:
        where_clauses.append("created_at >= %s")
        params.append(start_date)
    
    if end_date:
        where_clauses.append("created_at <= %s")
        params.append(end_date)
    
    if hashtags:
        # Handle hashtags array parameter - this may require special handling
        # For now, we'll skip this as it's more complex
        pass
    
    where_clause = " AND ".join(where_clauses)
    
    query = f"""
    SELECT 
        city,
        country,
        COUNT(*) AS tweet_count
    FROM tweets
    WHERE {where_clause}
    GROUP BY city, country
    ORDER BY tweet_count DESC
    LIMIT 10;
    """
    
    return execute_query(query, params if params else None)

# Main content
st.title("FanSense: Geo & Emotion-Based Fan Heatmaps")
st.markdown("""
Visualize fan engagement intensity and sentiment across geography and time.
This tool helps you understand how fans around the world react to events.
""")

# Sidebar filters
st.sidebar.header("Filters")

# Date range filter
start_date_db, end_date_db = get_date_range()

# Custom date range selector (better than the default)
min_date = start_date_db.date()
max_date = end_date_db.date()

# Calculate a reasonable default date range
default_end_date = max_date
default_start_date = max_date - timedelta(days=7)

# Allow selecting a start date in a wider range
start_date = st.sidebar.date_input(
    "Start Date",
    value=default_start_date,
    min_value=min_date,
    max_value=max_date
)

# End date should never be before the selected start date
end_date = st.sidebar.date_input(
    "End Date",
    value=default_end_date,
    min_value=start_date,
    max_value=max_date
)

# Convert to datetime for filtering
start_datetime = datetime.combine(start_date, datetime.min.time())
end_datetime = datetime.combine(end_date, datetime.max.time())

# Hashtag filter
available_hashtags = get_available_hashtags()
selected_hashtags = st.sidebar.multiselect(
    "Filter by Hashtags",
    options=available_hashtags,
    default=[]
)

# Emotion filter for map
emotion_options = ["All", "very_positive", "positive", "neutral", "negative", "very_negative"]
selected_emotion = st.sidebar.selectbox(
    "Filter by Emotion (Map Only)",
    options=emotion_options,
    index=0
)

emotion_filter = None if selected_emotion == "All" else selected_emotion

# Main content
col1, col2 = st.columns(2)

with col1:
    st.subheader("Sentiment Over Time")
    
    sentiment_data = get_sentiment_data(
        hashtags=selected_hashtags if selected_hashtags else None,
        start_date=start_datetime,
        end_date=end_datetime
    )
    
    if not sentiment_data.empty:
        # Pivot data for time series
        pivot_df = sentiment_data.pivot(index='time_bucket', columns='emotion', values='tweet_count').fillna(0)
        
        # Create time series chart
        fig = go.Figure()
        
        emotions_order = ['very_negative', 'negative', 'neutral', 'positive', 'very_positive']
        colors = {
            'very_negative': '#d32f2f',  # Red
            'negative': '#ff7043',       # Orange-red
            'neutral': '#ffd54f',        # Yellow
            'positive': '#66bb6a',       # Green
            'very_positive': '#1e88e5'   # Blue
        }
        
        for emotion in emotions_order:
            if emotion in pivot_df.columns:
                fig.add_trace(go.Scatter(
                    x=pivot_df.index,
                    y=pivot_df[emotion],
                    mode='lines',
                    name=emotion.replace('_', ' ').title(),
                    line=dict(color=colors.get(emotion))
                ))
        
        fig.update_layout(
            xaxis_title='Time',
            yaxis_title='Tweet Count',
            legend_title='Emotion',
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("No sentiment data available for the selected filters.")

with col2:
    st.subheader("Top Locations")
    
    top_locations = get_top_locations(
        hashtags=selected_hashtags if selected_hashtags else None,
        start_date=start_datetime,
        end_date=end_datetime
    )
    
    if not top_locations.empty:
        # Create bar chart
        fig = px.bar(
            top_locations,
            x='tweet_count',
            y='city',
            color='tweet_count',
            labels={'tweet_count': 'Tweet Count', 'city': 'City'},
            color_continuous_scale=px.colors.sequential.Viridis,
            orientation='h'
        )
        
        fig.update_layout(
            yaxis={'categoryorder': 'total ascending'},
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("No location data available for the selected filters.")

# Map visualization
st.subheader("Fan Sentiment Heatmap")

geo_data = get_geo_sentiment_data(
    hashtags=selected_hashtags if selected_hashtags else None,
    start_date=start_datetime,
    end_date=end_datetime,
    emotion=emotion_filter
)

if not geo_data.empty:
    # Create a color map for emotions
    emotion_colors = {
        'very_negative': 'red',
        'negative': 'orange',
        'neutral': 'yellow',
        'positive': 'lightgreen',
        'very_positive': 'darkgreen'
    }
    
    # Add color column
    if emotion_filter:
        geo_data['color'] = emotion_filter
    else:
        geo_data['color'] = geo_data['emotion'].map(emotion_colors)
    
    # Normalize marker size
    max_count = geo_data['tweet_count'].max()
    geo_data['marker_size'] = geo_data['tweet_count'] / max_count * 20 + 5  # Scale between 5 and 25
    
    # Create the map
    try:
        fig = px.scatter_mapbox(
            geo_data,
            lat='latitude',
            lon='longitude',
            size='marker_size',
            color='emotion',
            color_discrete_map=emotion_colors,
            hover_name='location_address',
            hover_data={
                'latitude': False,
                'longitude': False,
                'marker_size': False,
                'color': False,
                'city': True,
                'country': True,
                'tweet_count': True,
                'emotion': True
            },
            zoom=1
        )
        
        fig.update_layout(
            mapbox_style="carto-positron",
            height=600,
            margin={"r": 0, "t": 0, "l": 0, "b": 0}
        )
        
        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.error(f"Error creating map: {str(e)}")
        st.info("Could not create the map visualization. Displaying data as a table instead.")
        st.dataframe(geo_data)
else:
    st.info("No geo data available for the selected filters. Make sure tweets have been processed with geolocation.")

# Add sample tweets
st.subheader("Sample Tweets")

# Get sample tweets for the selected filters
where_clauses = []
params = []

if start_datetime:
    where_clauses.append("created_at >= %s")
    params.append(start_datetime)

if end_datetime:
    where_clauses.append("created_at <= %s")
    params.append(end_datetime)

if emotion_filter:
    where_clauses.append("emotion = %s")
    params.append(emotion_filter)

if selected_hashtags:
    # Handle hashtags array parameter - this may require special handling
    # For now, we'll skip this as it's more complex
    pass

where_clause = " AND ".join(where_clauses) if where_clauses else "1=1"

query = f"""
SELECT 
    text,
    username,
    created_at,
    emotion,
    location_raw
FROM tweets
WHERE {where_clause}
ORDER BY created_at DESC
LIMIT 10;
"""

sample_tweets = execute_query(query, params if params else None)

if not sample_tweets.empty:
    for index, row in sample_tweets.iterrows():
        with st.container():
            # Display tweet information
            st.markdown(f"**@{row['username']}**: {row['text']}")
            emotion_display = row['emotion'].replace('_', ' ').title() if row['emotion'] else 'Unknown'
            location_display = row['location_raw'] or 'Unknown'
            st.caption(f"{row['created_at']} | Sentiment: {emotion_display} | Location: {location_display}")
            
            # Use horizontal line instead of divider (compatible with older Streamlit)
            st.markdown("---")
else:
    st.info("No tweets available for the selected filters.")

# Footer
st.markdown("---")
st.caption("FanSense: Visualizing Fan Engagement Across Geography and Time")

# Debug info
if st.sidebar.checkbox("Show Debug Info", value=False):
    st.sidebar.subheader("Debug Information")
    try:
        conn = get_db_connection()
        if conn:
            st.sidebar.success("Database connection successful")
            
            # Count tweets
            count_query = "SELECT COUNT(*) FROM tweets"
            count_df = pd.read_sql_query(count_query, conn)
            st.sidebar.write(f"Total tweets in database: {count_df.iloc[0, 0]}")
            
            # Count tweets with sentiment
            sentiment_query = "SELECT COUNT(*) FROM tweets WHERE emotion IS NOT NULL"
            sentiment_df = pd.read_sql_query(sentiment_query, conn)
            st.sidebar.write(f"Tweets with sentiment: {sentiment_df.iloc[0, 0]}")
            
            # Count tweets with location
            location_query = "SELECT COUNT(*) FROM tweets WHERE latitude IS NOT NULL AND longitude IS NOT NULL"
            location_df = pd.read_sql_query(location_query, conn)
            st.sidebar.write(f"Tweets with location: {location_df.iloc[0, 0]}")
            
            conn.close()
        else:
            st.sidebar.error("Database connection failed")
    except Exception as e:
        st.sidebar.error(f"Database error: {str(e)}")
